def extract_weather_stations_nlp(html_content: str, mail_received_dt: str = None):
    logger.debug("Starting NLP extraction of weather stations.")
    soup = BeautifulSoup(html_content, "html.parser")
    text = soup.get_text("\n", strip=True)
    lines = [l.strip() for l in text.splitlines() if l.strip()]
 
    stations = []
    n = len(lines)
    i = 0
 
    logger.debug("Total lines extracted from HTML: %d", n)
 
    while i < n:
        line = lines[i]
 
        # Station code = exactly 3 uppercase letters
        if re.fullmatch(r"[A-Z]{3}", line):
            station_code = line
            logger.debug("Found potential station code at line %d: %s", i, station_code)
            entry = {"station": station_code}
 
            window = lines[i + 1: i + 15]
 
            # ---------- operationProbability (FIXED) ----------
            prob_val = None
 
            for w in window:
                m = re.search(r"(\d{1,3})\s*%", w)
                if m:
                    val = int(m.group(1))
                    if 0 <= val <= 100:
                        prob_val = val
                        logger.debug("Found operationProbability=%d for station=%s", prob_val, station_code)
                        break
 
            if prob_val is not None:
                entry["operationProbability"] = prob_val
 
            # ---------- weatherPhenomenon ----------
            for w in window:
                if re.fullmatch(r"[A-Z]{2,6}", w) and w != station_code:
                    entry["weatherPhenomenon"] = w
                    logger.debug("Found weatherPhenomenon=%s for station=%s", w, station_code)
                    break
 
            # ---------- advisory times (UTC only) ----------
            time_result = parse_advisory_times(window, mail_received_dt)
 
            if time_result:
                start_utc_str, end_utc_str = time_result
                start_utc_formatted = build_utc_from_dd_mon_hhmm(
                    re.match(r'(\d{3,4})/(\d{1,2})\s*([A-Za-z]{3})', start_utc_str),
                    parse_mail_received_datetime(mail_received_dt)
                )
                end_utc_formatted = build_utc_from_dd_mon_hhmm(
                    re.match(r'(\d{3,4})/(\d{1,2})\s*([A-Za-z]{3})', end_utc_str),
                    parse_mail_received_datetime(mail_received_dt)
                )
                entry["advisoryTimePeriodStartUTC"] = (
                    start_utc_formatted.strftime("%Y-%m-%dT%H:%M:%S")
                    if start_utc_formatted else start_utc_str
                )
                entry["advisoryTimePeriodEndUTC"] = (
                    end_utc_formatted.strftime("%Y-%m-%dT%H:%M:%S")
                    if end_utc_formatted else end_utc_str
                )
                logger.debug(
                    "Station=%s advisory times: start=%s end=%s",
                    station_code,
                    entry["advisoryTimePeriodStartUTC"],
                    entry["advisoryTimePeriodEndUTC"],
                )
 
            # Mandatory 5 fields only
            mandatory = [
                "station",
                "weatherPhenomenon",
                "operationProbability",
                "advisoryTimePeriodStartUTC",
                "advisoryTimePeriodEndUTC",
            ]
            if all(k in entry for k in mandatory):
                stations.append(entry)
                logger.info(
                    "Completed station entry: %s", entry
                )
            else:
                logger.info(
                    "Incomplete station entry for '%s', missing fields, ignoring: %s",
                    station_code,
                    [k for k in mandatory if k not in entry],
                )
 
        i += 1
 
    logger.info("NLP extraction complete. Total valid stations: %d", len(stations))
    return stations
 
